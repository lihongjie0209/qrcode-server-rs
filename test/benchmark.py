#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import time
import statistics
import threading
import json
import base64
from concurrent.futures import ThreadPoolExecutor, as_completed
import sys
from pathlib import Path

class QRCodeBenchmark:
    def __init__(self, base_url="http://localhost:3000"):
        self.base_url = base_url
        self.test_image_path = "test_qr.png"
        self.results = []
        
    def check_service_health(self):
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        try:
            response = requests.get(f"{self.base_url}/health?verbose=true", timeout=5)
            if response.status_code == 200:
                health_data = response.json()
                print("âœ… æœåŠ¡çŠ¶æ€æ­£å¸¸")
                print(f"ğŸ“Š æœåŠ¡ä¿¡æ¯: {health_data['service']} v{health_data['version']}")
                if 'pool_stats' in health_data:
                    pool_stats = health_data['pool_stats']
                    print(f"ğŸŠ å¯¹è±¡æ± é…ç½®: åˆå§‹å¤§å°={pool_stats['initial_size']}, æœ€å¤§å¤§å°={pool_stats['max_size']}")
                print(f"ğŸ”§ ç‰¹æ€§: {', '.join(health_data.get('features', {}).keys())}")
                return True
            else:
                print(f"âŒ æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥: HTTP {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡: {e}")
            return False
    
    def load_test_image(self):
        """åŠ è½½æµ‹è¯•å›¾ç‰‡"""
        if not Path(self.test_image_path).exists():
            print(f"âŒ æµ‹è¯•å›¾ç‰‡ä¸å­˜åœ¨: {self.test_image_path}")
            return None
        
        with open(self.test_image_path, 'rb') as f:
            return f.read()
    
    def single_request_file(self, image_data):
        """å•æ¬¡æ–‡ä»¶ä¸Šä¼ è¯·æ±‚"""
        # åˆ†é˜¶æ®µè®¡æ—¶
        start_time = time.time()
        prepare_start = time.time()
        
        try:
            files = {'file': ('test.png', image_data, 'image/png')}
            prepare_time = time.time() - prepare_start
            
            request_start = time.time()
            response = requests.post(f"{self.base_url}/detect/file", files=files, timeout=30)
            request_time = time.time() - request_start
            
            parse_start = time.time()
            if response.status_code == 200:
                data = response.json()
                parse_time = time.time() - parse_start
                
                end_time = time.time()
                total_client_time = (end_time - start_time) * 1000
                
                return {
                    'success': True,
                    'total_time': total_client_time,  # ms
                    'prepare_time': prepare_time * 1000,  # è¯·æ±‚å‡†å¤‡æ—¶é—´
                    'request_time': request_time * 1000,  # ç½‘ç»œ+æœåŠ¡å™¨æ—¶é—´
                    'parse_time': parse_time * 1000,     # å“åº”è§£ææ—¶é—´
                    'server_stats': data.get('statistics', {}),
                    'qr_count': data.get('count', 0),
                    'response_size': len(response.content)
                }
            else:
                end_time = time.time()
                return {
                    'success': False,
                    'total_time': (end_time - start_time) * 1000,
                    'error': f"HTTP {response.status_code}"
                }
        except Exception as e:
            end_time = time.time()
            return {
                'success': False,
                'total_time': (end_time - start_time) * 1000,
                'error': str(e)
            }
    
    def single_request_base64(self, image_data):
        """å•æ¬¡Base64è¯·æ±‚"""
        start_time = time.time()
        try:
            b64_data = base64.b64encode(image_data).decode('utf-8')
            payload = {'image': b64_data}
            response = requests.post(f"{self.base_url}/detect/base64", 
                                   json=payload, timeout=30)
            end_time = time.time()
            
            if response.status_code == 200:
                data = response.json()
                return {
                    'success': True,
                    'total_time': (end_time - start_time) * 1000,
                    'server_stats': data.get('statistics', {}),
                    'qr_count': data.get('count', 0)
                }
            else:
                return {
                    'success': False,
                    'total_time': (end_time - start_time) * 1000,
                    'error': f"HTTP {response.status_code}"
                }
        except Exception as e:
            end_time = time.time()
            return {
                'success': False,
                'total_time': (end_time - start_time) * 1000,
                'error': str(e)
            }
    
    def warmup(self, image_data, warmup_count=10):
        """é¢„çƒ­æµ‹è¯•"""
        print(f"ğŸ”¥ é¢„çƒ­æµ‹è¯• ({warmup_count} æ¬¡è¯·æ±‚)...")
        for i in range(warmup_count):
            self.single_request_file(image_data)
            print(f"   é¢„çƒ­è¿›åº¦: {i+1}/{warmup_count}", end='\r')
        print("âœ… é¢„çƒ­å®Œæˆ" + " " * 20)
    
    def benchmark_sequential(self, image_data, request_count=50):
        """ä¸²è¡ŒåŸºå‡†æµ‹è¯•"""
        print(f"\nğŸ“Š ä¸²è¡ŒåŸºå‡†æµ‹è¯• ({request_count} æ¬¡è¯·æ±‚)")
        print("-" * 60)
        
        results = []
        start_time = time.time()
        
        for i in range(request_count):
            result = self.single_request_file(image_data)
            results.append(result)
            print(f"   è¿›åº¦: {i+1}/{request_count} ({((i+1)/request_count*100):.1f}%)", end='\r')
        
        total_time = time.time() - start_time
        self.print_results("ä¸²è¡Œæµ‹è¯•", results, total_time)
        return results
    
    def benchmark_concurrent(self, image_data, concurrent_count=10, total_requests=100):
        """å¹¶å‘å‹åŠ›æµ‹è¯•"""
        print(f"\nğŸš€ å¹¶å‘å‹åŠ›æµ‹è¯• ({concurrent_count} å¹¶å‘, {total_requests} æ€»è¯·æ±‚)")
        print("-" * 60)
        
        results = []
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=concurrent_count) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = [executor.submit(self.single_request_file, image_data) 
                      for _ in range(total_requests)]
            
            # æ”¶é›†ç»“æœ
            completed = 0
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
                completed += 1
                print(f"   è¿›åº¦: {completed}/{total_requests} ({(completed/total_requests*100):.1f}%)", end='\r')
        
        total_time = time.time() - start_time
        self.print_results(f"å¹¶å‘æµ‹è¯• ({concurrent_count}å¹¶å‘)", results, total_time)
        return results
    
    def benchmark_mixed_api(self, image_data, concurrent_count=10, total_requests=100):
        """æ··åˆAPIæµ‹è¯•ï¼ˆæ–‡ä»¶ä¸Šä¼  + Base64ï¼‰"""
        print(f"\nğŸ”€ æ··åˆAPIæµ‹è¯• ({concurrent_count} å¹¶å‘, {total_requests} æ€»è¯·æ±‚)")
        print("-" * 60)
        
        results = []
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=concurrent_count) as executor:
            futures = []
            # äº¤æ›¿ä½¿ç”¨æ–‡ä»¶ä¸Šä¼ å’ŒBase64 API
            for i in range(total_requests):
                if i % 2 == 0:
                    futures.append(executor.submit(self.single_request_file, image_data))
                else:
                    futures.append(executor.submit(self.single_request_base64, image_data))
            
            completed = 0
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
                completed += 1
                print(f"   è¿›åº¦: {completed}/{total_requests} ({(completed/total_requests*100):.1f}%)", end='\r')
        
        total_time = time.time() - start_time
        self.print_results("æ··åˆAPIæµ‹è¯•", results, total_time)
        return results
    
    def sustained_load_test(self, image_data, concurrent_count=5, duration_seconds=30):
        """æŒç»­è´Ÿè½½æµ‹è¯•"""
        print(f"\nâ±ï¸  æŒç»­è´Ÿè½½æµ‹è¯• ({concurrent_count} å¹¶å‘, {duration_seconds} ç§’)")
        print("-" * 60)
        
        results = []
        start_time = time.time()
        end_time = start_time + duration_seconds
        
        def worker():
            while time.time() < end_time:
                result = self.single_request_file(image_data)
                results.append(result)
        
        threads = []
        for _ in range(concurrent_count):
            thread = threading.Thread(target=worker)
            threads.append(thread)
            thread.start()
        
        # ç›‘æ§è¿›åº¦
        while time.time() < end_time:
            elapsed = time.time() - start_time
            remaining = duration_seconds - elapsed
            print(f"   è¿è¡Œä¸­: {elapsed:.1f}s / {duration_seconds}s, å·²å®Œæˆ: {len(results)} è¯·æ±‚", end='\r')
            time.sleep(1)
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        total_time = time.time() - start_time
        self.print_results("æŒç»­è´Ÿè½½æµ‹è¯•", results, total_time)
        return results
    
    def print_results(self, test_name, results, total_time):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print("\n" + " " * 80)  # æ¸…é™¤è¿›åº¦æ˜¾ç¤º
        
        successful_results = [r for r in results if r['success']]
        failed_count = len(results) - len(successful_results)
        
        if not successful_results:
            print(f"âŒ {test_name}: æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†!")
            return
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        client_times = [r['total_time'] for r in successful_results]
        server_times = [r['server_stats'].get('total_time_ms', 0) for r in successful_results if 'server_stats' in r]
        decode_times = [r['server_stats'].get('image_decode_time_ms', 0) for r in successful_results if 'server_stats' in r]
        detection_times = [r['server_stats'].get('detection_time_ms', 0) for r in successful_results if 'server_stats' in r]
        pool_times = [r['server_stats'].get('pool_acquisition_time_ms', 0) for r in successful_results if 'server_stats' in r]
        
        qps = len(successful_results) / total_time if total_time > 0 else 0
        
        print(f"ğŸ“ˆ {test_name} ç»“æœ:")
        print(f"   æ€»è¯·æ±‚æ•°: {len(results)}")
        print(f"   æˆåŠŸè¯·æ±‚: {len(successful_results)}")
        print(f"   å¤±è´¥è¯·æ±‚: {failed_count}")
        print(f"   æ€»è€—æ—¶: {total_time:.2f}s")
        print(f"   QPS: {qps:.2f}")
        
        if client_times:
            print(f"\n   å®¢æˆ·ç«¯å“åº”æ—¶é—´ (ms):")
            print(f"     å¹³å‡: {statistics.mean(client_times):.2f}")
            print(f"     ä¸­ä½æ•°: {statistics.median(client_times):.2f}")
            print(f"     æœ€å°: {min(client_times):.2f}")
            print(f"     æœ€å¤§: {max(client_times):.2f}")
            print(f"     95%: {self.percentile(client_times, 95):.2f}")
            print(f"     99%: {self.percentile(client_times, 99):.2f}")
            
            # è¯¦ç»†æ—¶é—´åˆ†è§£
            prepare_times = [r.get('prepare_time', 0) for r in successful_results if 'prepare_time' in r]
            request_times = [r.get('request_time', 0) for r in successful_results if 'request_time' in r]
            parse_times = [r.get('parse_time', 0) for r in successful_results if 'parse_time' in r]
            response_sizes = [r.get('response_size', 0) for r in successful_results if 'response_size' in r]
            
            if prepare_times and request_times and parse_times:
                print(f"\n   æ—¶é—´åˆ†è§£åˆ†æ (ms):")
                print(f"     è¯·æ±‚å‡†å¤‡æ—¶é—´: {statistics.mean(prepare_times):.3f}")
                print(f"     ç½‘ç»œ+æœåŠ¡å™¨æ—¶é—´: {statistics.mean(request_times):.2f}")
                print(f"     å“åº”è§£ææ—¶é—´: {statistics.mean(parse_times):.3f}")
                
                # è®¡ç®—ç½‘ç»œå¼€é”€
                network_overhead = statistics.mean(request_times) - statistics.mean(server_times) if server_times else 0
                print(f"     ç½‘ç»œ+HTTPå¼€é”€: {network_overhead:.2f}")
                
            if response_sizes:
                print(f"     å¹³å‡å“åº”å¤§å°: {statistics.mean(response_sizes):.0f} bytes")
        
        if server_times:
            print(f"\n   æœåŠ¡ç«¯å¤„ç†æ—¶é—´ (ms):")
            print(f"     æ€»æ—¶é—´å¹³å‡: {statistics.mean(server_times):.2f}")
            print(f"     è§£ç æ—¶é—´å¹³å‡: {statistics.mean(decode_times):.2f}")
            print(f"     æ£€æµ‹æ—¶é—´å¹³å‡: {statistics.mean(detection_times):.2f}")
            if pool_times and any(t > 0 for t in pool_times):
                print(f"     å¯¹è±¡æ± è·å–æ—¶é—´å¹³å‡: {statistics.mean(pool_times):.3f}")
        
        if failed_count > 0:
            print(f"\n   âš ï¸  å¤±è´¥åŸå› ç»Ÿè®¡:")
            failed_results = [r for r in results if not r['success']]
            error_counts = {}
            for r in failed_results:
                error = r.get('error', 'Unknown')
                error_counts[error] = error_counts.get(error, 0) + 1
            for error, count in error_counts.items():
                print(f"     {error}: {count}")
    
    def percentile(self, data, percentile):
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        size = len(data)
        return sorted(data)[int(size * percentile / 100)]
    
    def run_all_benchmarks(self):
        """è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•"""
        print("=" * 80)
        print("ğŸ¯ QRç æœåŠ¡å™¨æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("=" * 80)
        
        # æ£€æŸ¥æœåŠ¡çŠ¶æ€
        if not self.check_service_health():
            sys.exit(1)
        
        # åŠ è½½æµ‹è¯•å›¾ç‰‡
        image_data = self.load_test_image()
        if image_data is None:
            sys.exit(1)
        
        print(f"ğŸ“¸ æµ‹è¯•å›¾ç‰‡å¤§å°: {len(image_data)} bytes")
        
        # é¢„çƒ­
        self.warmup(image_data)
        
        # å„ç§åŸºå‡†æµ‹è¯•
        self.benchmark_sequential(image_data, 20)
        self.benchmark_concurrent(image_data, 5, 50)
        self.benchmark_concurrent(image_data, 10, 100)
        self.benchmark_concurrent(image_data, 20, 200)
        self.benchmark_mixed_api(image_data, 10, 100)
        self.sustained_load_test(image_data, 10, 20)
        
        print("\n" + "=" * 80)
        print("âœ¨ æ‰€æœ‰åŸºå‡†æµ‹è¯•å®Œæˆ!")
        print("=" * 80)

if __name__ == "__main__":
    benchmark = QRCodeBenchmark()
    benchmark.run_all_benchmarks()
