#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import time
import statistics
import json

def detailed_timing_analysis():
    """è¯¦ç»†çš„æ—¶é—´åˆ†æ"""
    print("ğŸ” è¯¦ç»†æ—¶é—´åˆ†ææµ‹è¯•")
    print("=" * 50)
    
    # åŠ è½½æµ‹è¯•å›¾ç‰‡
    with open("test_qr.png", 'rb') as f:
        image_data = f.read()
    
    results = []
    
    # è¿›è¡Œ10æ¬¡æµ‹è¯•
    for i in range(10):
        print(f"æµ‹è¯• {i+1}/10...", end=' ')
        
        # è¯¦ç»†è®¡æ—¶
        total_start = time.time()
        
        # 1. å‡†å¤‡è¯·æ±‚
        prepare_start = time.time()
        files = {'file': ('test.png', image_data, 'image/png')}
        prepare_time = (time.time() - prepare_start) * 1000
        
        # 2. å‘é€è¯·æ±‚å’Œæ¥æ”¶å“åº”
        request_start = time.time()
        response = requests.post("http://localhost:3000/detect/file", files=files)
        request_time = (time.time() - request_start) * 1000
        
        # 3. è§£æå“åº”
        parse_start = time.time()
        data = response.json()
        parse_time = (time.time() - parse_start) * 1000
        
        total_time = (time.time() - total_start) * 1000
        
        server_stats = data.get('statistics', {})
        
        result = {
            'total_client_time': total_time,
            'prepare_time': prepare_time,
            'request_time': request_time, 
            'parse_time': parse_time,
            'server_total_time': server_stats.get('total_time_ms', 0),
            'server_decode_time': server_stats.get('image_decode_time_ms', 0),
            'server_detection_time': server_stats.get('detection_time_ms', 0),
            'server_pool_time': server_stats.get('pool_acquisition_time_ms', 0),
            'response_size': len(response.content)
        }
        
        results.append(result)
        print(f"æ€»æ—¶é—´: {total_time:.1f}ms, æœåŠ¡å™¨: {result['server_total_time']:.1f}ms")
    
    # ç»Ÿè®¡åˆ†æ
    print("\nğŸ“Š æ—¶é—´åˆ†è§£ç»Ÿè®¡:")
    print("-" * 50)
    
    metrics = [
        ('å®¢æˆ·ç«¯æ€»æ—¶é—´', 'total_client_time'),
        ('è¯·æ±‚å‡†å¤‡æ—¶é—´', 'prepare_time'), 
        ('ç½‘ç»œ+æœåŠ¡å™¨æ—¶é—´', 'request_time'),
        ('å“åº”è§£ææ—¶é—´', 'parse_time'),
        ('æœåŠ¡å™¨æ€»æ—¶é—´', 'server_total_time'),
        ('æœåŠ¡å™¨è§£ç æ—¶é—´', 'server_decode_time'),
        ('æœåŠ¡å™¨æ£€æµ‹æ—¶é—´', 'server_detection_time'),
        ('å¯¹è±¡æ± è·å–æ—¶é—´', 'server_pool_time')
    ]
    
    for name, key in metrics:
        values = [r[key] for r in results]
        if any(v > 0 for v in values):
            avg = statistics.mean(values)
            print(f"{name:15}: {avg:8.3f}ms")
    
    # è®¡ç®—ç½‘ç»œå¼€é”€
    client_request_avg = statistics.mean([r['request_time'] for r in results])
    server_total_avg = statistics.mean([r['server_total_time'] for r in results])
    network_overhead = client_request_avg - server_total_avg
    
    print(f"\nğŸŒ ç½‘ç»œ+HTTPå¼€é”€åˆ†æ:")
    print(f"ç½‘ç»œ+æœåŠ¡å™¨æ—¶é—´: {client_request_avg:.2f}ms")
    print(f"æœåŠ¡å™¨å¤„ç†æ—¶é—´:   {server_total_avg:.2f}ms") 
    print(f"ç½‘ç»œ+HTTPå¼€é”€:    {network_overhead:.2f}ms ({network_overhead/client_request_avg*100:.1f}%)")
    
    # å“åº”å¤§å°
    avg_response_size = statistics.mean([r['response_size'] for r in results])
    print(f"å¹³å‡å“åº”å¤§å°:     {avg_response_size:.0f} bytes")

if __name__ == "__main__":
    detailed_timing_analysis()
